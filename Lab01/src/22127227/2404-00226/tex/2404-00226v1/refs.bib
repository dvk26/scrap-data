@inproceedings{ConVIRT,
  title={Contrastive learning of medical visual representations from paired images and text},
  author={Zhang, Yuhao and Jiang, Hang and Miura, Yasuhide and others},
  booktitle={Machine Learning for Healthcare Conference},
  pages={2--25},
  year={2020},
  organization={PMLR}
}

@inproceedings{GLoRIA,
  title={Gloria: A multimodal global-local representation learning framework for label-efficient medical image recognition},
  author={Huang, Shih-Cheng and Shen, Liyue and Lungren, Matthew P and others},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3942--3951},
  year={2021}
}

@article{LViT,
  title={Lvit: language meets vision transformer in medical image segmentation},
  author={Li, Zihan and Li, Yunxiang and Li, Qingde and Wang, Puyang and Guo, Dazhou and Lu, Le and Jin, Dakai and Zhang, You and Hong, Qingqi},
  journal={IEEE Transactions on Medical Imaging},
  year={2023},
  publisher={IEEE}
}

@article{MedCLIP,
  title={Medclip: Contrastive learning from unpaired medical images and text},
  author={Wang, Zifeng and Wu, Zhenbang and Agarwal, Dinesh and others},
  journal={Conference on Empirical Methods in Natural Language Processing},
  year={2022}
}

@article{MGCA,
  title={Multi-granularity cross-modal alignment for generalized medical visual representation learning},
  author={Wang, Fuying and Zhou, Yuyin and Wang, Shujun and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={33536--33549},
  year={2022}
}

@article{REFERS,
  title={Generalized radiograph representation learning via cross-supervision between images and free-text radiology reports},
  author={Zhou, Hong-Yu and Chen, Xiaoyu and Zhang, Yinghao and Luo, Ruibang and Wang, Liansheng and Yu, Yizhou},
  journal={Nature Machine Intelligence},
  volume={4},
  number={1},
  pages={32--40},
  year={2022},
  publisher={Nature Publishing Group UK London}
}

@article{YOLOv4,
  title={Yolov4: Optimal speed and accuracy of object detection},
  author={Bochkovskiy, Alexey and Wang, Chien-Yao and Liao, Hong-Yuan Mark},
  journal={arXiv preprint arXiv:2004.10934},
  year={2020}
}

@article{M3AE,
  title={Multimodal masked autoencoders learn transferable representations},
  author={Geng, Xinyang and Liu, Hao and Lee, Lisa and Schuurmans, Dale and Levine, Sergey and Abbeel, Pieter},
  journal={arXiv preprint arXiv:2205.14204},
  year={2022}
}

@article{IRinmedical,
  title={Self-supervised learning for medical image analysis using image context restoration},
  author={Chen, Liang and Bentley, Paul and Mori, Kensaku and Misawa, Kazunari and Fujiwara, Michitaka and Rueckert, Daniel},
  journal={Medical image analysis},
  volume={58},
  pages={101539},
  year={2019},
  publisher={Elsevier}
}

@inproceedings{MAE,
  title={Masked autoencoders are scalable vision learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={16000--16009},
  year={2022}
}

@inproceedings{VinVL,
  title={Vinvl: Revisiting visual representations in vision-language models},
  author={Zhang, Pengchuan and Li, Xiujun and Hu, Xiaowei and Yang, Jianwei and Zhang, Lei and Wang, Lijuan and Choi, Yejin and Gao, Jianfeng},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={5579--5588},
  year={2021}
}

@article{VisualBERT,
  title={Visualbert: A simple and performant baseline for vision and language},
  author={Li, Liunian Harold and Yatskar, Mark and Yin, Da and Hsieh, Cho-Jui and Chang, Kai-Wei},
  journal={arXiv preprint arXiv:1908.03557},
  year={2019}
}

@article{VLBERT,
  title={Vl-bert: Pre-training of generic visual-linguistic representations},
  author={Su, Weijie and Zhu, Xizhou and Cao, Yue and Li, Bin and Lu, Lewei and Wei, Furu and Dai, Jifeng},
  journal={arXiv preprint arXiv:1908.08530},
  year={2019}
}

@inproceedings{CLIP,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{CoCa,
  title={Coca: Contrastive captioners are image-text foundation models},
  author={Yu, Jiahui and Wang, Zirui and Vasudevan, Vijay and Yeung, Legg and Seyedhosseini, Mojtaba and Wu, Yonghui},
  journal={arXiv preprint arXiv:2205.01917},
  year={2022}
}

@article{ALBEF,
  title={Align before fuse: Vision and language representation learning with momentum distillation},
  author={Li, Junnan and Selvaraju, Ramprasaath and Gotmare, Akhilesh and others},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={9694--9705},
  year={2021}
}

@article{FILIP,
  title={Filip: Fine-grained interactive language-image pre-training},
  author={Yao, Lewei and Huang, Runhui and Hou, Lu and Lu, Guansong and Niu, Minzhe and Xu, Hang and Liang, Xiaodan and Li, Zhenguo and Jiang, Xin and Xu, Chunjing},
  journal={arXiv preprint arXiv:2111.07783},
  year={2021}
}

@article{LOUPE,
  title={Fine-grained semantically aligned vision-language pre-training},
  author={Li, Juncheng and He, Xin and Wei, Longhui and Qian, Long and Zhu, Linchao and Xie, Lingxi and Zhuang, Yueting and Tian, Qi and Tang, Siliang},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={7290--7303},
  year={2022}
}

@article{UniVL,
  title={Univl: A unified video and language pre-training model for multimodal understanding and generation},
  author={Luo, Huaishao and Ji, Lei and Shi, Botian and Huang, Haoyang and Duan, Nan and Li, Tianrui and Li, Jason and Bharti, Taroon and Zhou, Ming},
  journal={arXiv preprint arXiv:2002.06353},
  year={2020}
}

@article{X-VLM,
  title={Multi-grained vision language pre-training: Aligning texts with visual concepts},
  author={Zeng, Yan and Zhang, Xinsong and Li, Hang},
  journal={arXiv preprint arXiv:2111.08276},
  year={2021}
}

@article{FNNLM,
  title={A neural probabilistic language model},
  author={Bengio, Yoshua and Ducharme, R{\'e}jean and Vincent, Pascal},
  journal={Advances in neural information processing systems},
  volume={13},
  year={2000}
}

@inproceedings{RNNLM,
  title={Recurrent neural network based language model.},
  author={Mikolov, Tomas and Karafi{\'a}t, Martin and Burget, Lukas and Cernock{\`y}, Jan and Khudanpur, Sanjeev},
  booktitle={Interspeech},
  volume={2},
  number={3},
  pages={1045--1048},
  year={2010},
  organization={Makuhari}
}

@article{transformer,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and others},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{GPT,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and others},
  year={2018},
  publisher={OpenAI}
}

@article{GPT2,
  title={Language Models are Unsupervised Multitask Learners},
  author={Radford, Alec and Wu, Jeff and Child, Rewon and others},
  year={2019}
}

@article{GPT3,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{InstructGPT,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{BERT,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and others},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{ERNIE,
  title={Ernie: Enhanced representation through knowledge integration},
  author={Sun, Yu and Wang, Shuohuan and Li, Yukun and Feng, Shikun and Chen, Xuyi and Zhang, Han and Tian, Xin and Zhu, Danxiang and Tian, Hao and Wu, Hua},
  journal={arXiv preprint arXiv:1904.09223},
  year={2019}
}


@article{autoencoder,
  title={Reducing the dimensionality of data with neural networks},
  author={Hinton, Geoffrey E and Salakhutdinov, Ruslan R},
  journal={science},
  volume={313},
  number={5786},
  pages={504--507},
  year={2006},
  publisher={American Association for the Advancement of Science}
}

@article{ViT,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and others},
  journal={International Conference on Learning Representations},
  year={2020}
}

@article{ERNIE-health-zh,
  title={Building chinese biomedical language models via multi-level text discrimination},
  author={Wang, Quan and Dai, Songtai and Xu, Benfeng and others},
  journal={arXiv preprint arXiv:2110.07244},
  year={2021}
}

@inproceedings{ResNet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and others},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{BUSI,
  title={Dataset of breast ultrasound images},
  author={Al-Dhabyani, Walid and Gomaa, Mohammed and Khaled, Hussien and Fahmy, Aly},
  journal={Data in brief},
  volume={28},
  pages={104863},
  year={2020},
  publisher={Elsevier}
}

@inproceedings{DDTI,
  title={An open access thyroid ultrasound image database},
  author={Pedraza, Lina and Vargas, Carlos and Narv{\'a}ez, Fabi{\'a}n and others},
  booktitle={10th International symposium on medical information processing and analysis},
  volume={9287},
  pages={188--193},
  year={2015},
  organization={SPIE}
}

@article{YOLOv3,
  title={Yolov3: An incremental improvement},
  author={Redmon, Joseph and Farhadi, Ali},
  journal={arXiv preprint arXiv:1804.02767},
  year={2018}
}

@inproceedings{UNet,
  title={U-net: Convolutional networks for biomedical image segmentation},
  author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  booktitle={Medical Image Computing and Computer-Assisted Intervention--MICCAI 2015: 18th International Conference, Munich, Germany, October 5-9, 2015, Proceedings, Part III 18},
  pages={234--241},
  year={2015},
  organization={Springer}
}

@article{AdamW,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1711.05101},
  year={2017}
}

@inproceedings{SETR,
  title={Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers},
  author={Zheng, Sixiao and Lu, Jiachen and Zhao, Hengshuang and Zhu, Xiatian and Luo, Zekun and Wang, Yabiao and Fu, Yanwei and Feng, Jianfeng and Xiang, Tao and Torr, Philip HS and others},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={6881--6890},
  year={2021}
}

@article{n-gram,
  title={A statistical approach to mechanized encoding and searching of literary information},
  author={Luhn, Hans Peter},
  journal={IBM Journal of research and development},
  volume={1},
  number={4},
  pages={309--317},
  year={1957},
  publisher={IBM}
}

@inproceedings{TCL,
  title={Vision-language pre-training with triple contrastive learning},
  author={Yang, Jinyu and Duan, Jiali and Tran, Son and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15671--15680},
  year={2022}
}

@inproceedings{Softmask,
  title={Multi-Modal Representation Learning with Text-Driven Soft Masks},
  author={Park, Jaeyoo and Han, Bohyung},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2798--2807},
  year={2023}
}

@inproceedings{UNITER,
  title={Uniter: Universal image-text representation learning},
  author={Chen, Yen-Chun and Li, Linjie and Yu, Licheng and El Kholy, Ahmed and Ahmed, Faisal and Gan, Zhe and Cheng, Yu and Liu, Jingjing},
  booktitle={European conference on computer vision},
  pages={104--120},
  year={2020},
  organization={Springer}
}

@inproceedings{BLIP,
  title={Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation},
  author={Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven},
  booktitle={International Conference on Machine Learning},
  pages={12888--12900},
  year={2022},
  organization={PMLR}
}

@inproceedings{MAGE,
  title={Mage: Masked generative encoder to unify representation learning and image synthesis},
  author={Li, Tianhong and Chang, Huiwen and Mishra, Shlok and Zhang, Han and Katabi, Dina and Krishnan, Dilip},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2142--2152},
  year={2023}
}

@inproceedings{ImageNet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}

@article{XrayGPT,
  title={Xraygpt: Chest radiographs summarization using medical vision-language models},
  author={Thawkar, Omkar and Shaker, Abdelrahman and Mullappilly, Sahal Shaji and Cholakkal, Hisham and Anwer, Rao Muhammad and Khan, Salman and Laaksonen, Jorma and Khan, Fahad Shahbaz},
  journal={arXiv preprint arXiv:2306.07971},
  year={2023}
}

@article{X-LLM,
  title={X-llm: Bootstrapping advanced large language models by treating multi-modalities as foreign languages},
  author={Chen, Feilong and Han, Minglun and Zhao, Haozhi and Zhang, Qingyang and Shi, Jing and Xu, Shuang and Xu, Bo},
  journal={arXiv preprint arXiv:2305.04160},
  year={2023}
}

@article{si2023combo,
  title={Combo of Thinking and Observing for Outside-Knowledge VQA},
  author={Si, Qingyi and Mo, Yuchen and Lin, Zheng and Ji, Huishan and Wang, Weiping},
  journal={arXiv preprint arXiv:2305.06407},
  year={2023}
}

@article{BLIP2,
  title={{BLIP-2:} Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models}, 
  author={Junnan Li and Dongxu Li and Silvio Savarese and others},
  year={2023},
  booktitle={ICML},
}

@article{CNN-LSTM,
  title={On the automatic generation of medical imaging reports},
  author={Jing, Baoyu and Xie, Pengtao and Xing, Eric},
  journal={Annual Meeting of the Association for Computational Linguistics},
  year={2017}
}

@article{R2Gen,
  title={Generating radiology reports via memory-driven transformer},
  author={Chen, Zhihong and Song, Yan and Chang, Tsung-Hui and others},
  journal={Conference on Empirical Methods in Natural Language Processing},
  year={2020}
}

@article{TriNet,
  title={Joint embedding of deep visual and semantic features for medical image report generation},
  author={Yang, Yan and Yu, Jun and Zhang, Jian and others},
  journal={IEEE Transactions on Multimedia},
  year={2021},
  publisher={IEEE}
}

@article{UER,
  title={UER: An Open-Source Toolkit for Pre-training Models},
  author={Zhao, Zhe and Chen, Hui and Zhang, Jinbin and others},
  journal={Conference on Empirical Methods in Natural Language Processing-International Joint Conference on Natural Language Processing},
  pages={241},
  year={2019}
}

@article{Tencentpretrain,
  title={TencentPretrain: A Scalable and Flexible Toolkit for Pre-training Models of Different Modalities},
  author={Zhao, Zhe and Li, Yudong and Hou, Cheng and others},
  journal={Annual Meeting of the Association for Computational Linguistics},
  pages={217},
  year={2023}
}

@article{Sgdr,
  title={Sgdr: Stochastic gradient descent with warm restarts},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1608.03983},
  year={2016}
}

@inproceedings{SGF,
  title={A self-guided framework for radiology report generation},
  author={Li, Jun and Li, Shibo and Hu, Ying and others},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={588--598},
  year={2022},
  organization={Springer}
}

@inproceedings{SDG,
  title={More control for free! image synthesis with semantic diffusion guidance},
  author={Liu, Xihui and Park, Dong Huk and Azadi, Samaneh and Zhang, Gong and Chopikyan, Arman and Hu, Yuxiao and Shi, Humphrey and Rohrbach, Anna and Darrell, Trevor},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={289--299},
  year={2023}
}

@inproceedings{BlendedDiffusion,
  title={Blended diffusion for text-driven editing of natural images},
  author={Avrahami, Omri and Lischinski, Dani and Fried, Ohad},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18208--18218},
  year={2022}
}

@inproceedings{DiffusionCLIP,
  title={Diffusionclip: Text-guided diffusion models for robust image manipulation},
  author={Kim, Gwanghyun and Kwon, Taesung and Ye, Jong Chul},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2426--2435},
  year={2022}
}

@article{InfoNCE,
  title={Representation learning with contrastive predictive coding},
  author={Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1807.03748},
  year={2018}
}

@article{Mini-gpt4,
  title={Minigpt-4: Enhancing vision-language understanding with advanced large language models},
  author={Zhu, Deyao and Chen, Jun and Shen, Xiaoqian and Li, Xiang and Elhoseiny, Mohamed},
  journal={arXiv preprint arXiv:2304.10592},
  year={2023}
}

@inproceedings{RGRG,
  title={Interactive and Explainable Region-guided Radiology Report Generation},
  author={Tanida, Tim and M{\"u}ller, Philip and Kaissis, Georgios and Rueckert, Daniel},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7433--7442},
  year={2023}
}

@inproceedings{CMITM,
  title={Contrastive Masked Image-Text Modeling for Medical Visual Representation Learning},
  author={Chen, Cheng and Zhong, Aoxiao and Wu, Dufan and others},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={493--503},
  year={2023},
  organization={Springer}
}

@article{MRM,
  title={Advancing radiograph representation learning with masked record modeling},
  author={Zhou, Hong-Yu and Lian, Chenyu and Wang, Liansheng and others},
  journal={International Conference on Learning Representations},
  year={2023}
}

@article{DeblurringMAE,
  title={Deblurring Masked Autoencoder is Better Recipe for Ultrasound Image Recognition},
  author={Kang, Qingbo and Gao, Jun and Li, Kang and Lao, Qicheng},
  journal={arXiv preprint arXiv:2306.08249},
  year={2023}
}

@inproceedings{MedVQA,
  title={Contrastive pre-training and representation distillation for medical visual question answering based on radiology images},
  author={Liu, Bo and Zhan, Li-Ming and Wu, Xiao-Ming},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={210--220},
  year={2021},
  organization={Springer}
}

@inproceedings{BLEU,
  title={Bleu: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and others},
  journal={Annual Meeting of the Association for Computational Linguistics},
  year={2002}
}

@inproceedings{ROUGE-L,
  title={Rouge: A package for automatic evaluation of summaries},
  author={Lin, Chin-Yew},
  booktitle={Text summarization branches out},
  pages={74--81},
  year={2004}
}

@inproceedings{METEOR,
  title={METEOR: An automatic metric for MT evaluation with improved correlation with human judgments},
  author={Banerjee, Satanjeev and Lavie, Alon},
  booktitle={Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization},
  pages={65--72},
  year={2005}
}

@article{DeltaNet,
  title={DeltaNet: Conditional medical report generation for COVID-19 diagnosis},
  author={Wu, Xian and Yang, Shuxin and Qiu, Zhaopeng and others},
  journal={International Conference On Computational Linguistics},
  year={2022}
}

@article{MedVQALLM,
  title={Open-ended medical visual question answering through prefix tuning of language models},
  author={van Sonsbeek, Tom and Derakhshani, Mohammad Mahdi and Najdenkoska, Ivona and others},
  journal={arXiv preprint arXiv:2303.05977},
  year={2023}
}

@article{WSDAN,
  title={A Dual-Attention Learning Network with Word and Sentence Embedding for Medical Visual Question Answering},
  author={Huang, Xiaofei and Gong, Hongfang},
  journal={IEEE Transactions on Medical Imaging},
  year={2023},
  publisher={IEEE}
}

@inproceedings{CAT-ViL,
  title={CAT-ViL: Co-attention Gated Vision-Language Embedding for Visual Question Localized-Answering in Robotic Surgery},
  author={Bai, Long and Islam, Mobarakol and Ren, Hongliang},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={397--407},
  year={2023},
  organization={Springer}
}

@inproceedings{CMNRL,
  title={Reinforced cross-modal alignment for radiology report generation},
  author={Qin, Han and Song, Yan},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2022},
  pages={448--458},
  year={2022}
}

@online{ChatGPT,
  author = {OpenAI},
  title = {Introducing ChatGPT},
  year = {2023},
  url = {https://openai.com/blog/chatgpt/},
  note = {Accessed on January 10, 2023},
}

@online{AUITD,
  author = {AZOUZ Maroua},
  title = {Algerian Ultrasound Images Thyroid Dataset: AUITD},
  year = {2022},
  note = {Accessed on February 10, 2023},
  url = {https://www.kaggle.com/azouzmaroua/datasets},
}

@inproceedings{Repsnet,
  title={RepsNet: Combining Vision with Language for Automated Medical Reports},
  author={Tanwani, Ajay K and Barral, Joelle and Freedman, Daniel},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={714--724},
  year={2022},
  organization={Springer}
}

@inproceedings{ClinicalBERT,
  title={Clinical-BERT: Vision-language pre-training for radiograph diagnosis and reports generation},
  author={Yan, Bin and Pei, Mingtao},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  number={3},
  pages={2982--2990},
  year={2022}
}

@inproceedings{MedIM,
  title={MedIM: Boost Medical Image Representation via Radiology Report-Guided Masking},
  author={Xie, Yutong and Gu, Lin and Harada, Tatsuya and others},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={13--23},
  year={2023},
  organization={Springer}
}

@article{MME,
  title={Mme: A comprehensive evaluation benchmark for multimodal large language models},
  author={Fu, Chaoyou and Chen, Peixian and Shen, Yunhang and others},
  journal={arXiv preprint arXiv:2306.13394},
  year={2023}
}

@article{MLLMsurvey,
  title={A Survey on Multimodal Large Language Models},
  author={Yin, Shukang and Fu, Chaoyou and Zhao, Sirui and Li, Ke and Sun, Xing and Xu, Tong and Chen, Enhong},
  journal={arXiv preprint arXiv:2306.13549},
  year={2023}
}

@inproceedings{R2GenRL,
  title={Reinforced cross-modal alignment for radiology report generation},
  author={Qin, Han and Song, Yan},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2022},
  pages={448--458},
  year={2022}
}
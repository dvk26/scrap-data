
\section{Future Directions}
The past years have witnessed the rapid development of heterogeneous CL on foundation models. Building upon such progress, it opens the door to many exciting future opportunities to explore in this emerging area. Here, we summarize five promising future directions, focusing on contrastive foundation models. % due to the space limitation, though there are lots of interesting future research directions to pursue.
%\hh{1. can we add a short paragraph, to first briefly summarize the survey and then point out there are a lot of interesting future directions to pursue, such as ...? 2. consider to revise the heading of each future direction so that their connection to CL is clear from the heading. for instace, instead of 'trustworthiness', can we call it 'trustworthy contrastive learning'? in this way, the readers will be clear that we are talking about these topics in the context of CL (instead of a general introduction of e.g., trustworthy ML).} \lc{Sure. I will update this section soon.}

\textbf{Representation Redundancy and Uniqueness for CL Model.}
The current CL models mainly extract the shared representation by maximizing the similarity of two views for the same sample. However, some recent works~\cite{DBLP:conf/nips/LiangDMZMS23, zheng2024multi} have suggested the potential of extracting uniqueness via CL to improve the performance of the downstream tasks. However, the initial methods are only used to deal with the small model, and how to naturally combine it with foundation models remains a great challenge due to the extra computational cost and limited performance improvement at the current stage.

\textbf{Efficiency of CL Foundation Models.}
One major issue of training the foundation models with CL loss is the high GPU memory requirement as discussed in Section~\ref{Large_vision_model}. 
% The time complexity of most CL methods requires $O(n^2)$ to compute the similarity matrix for both positive and negative pairs, where $n$ is the number of samples.
Recently, Zeroth order optimization methods~\cite{malladi2024fine} have shown great potential to alleviate the computational cost by replacing the traditional forward-passing and backward-passing optimization scheme with a forward-passing-only optimization scheme. However, the zeroth order optimizer usually sacrifices the optimization efficiency for lower GPU requirements, as it requires significantly more steps than standard fine-tuning~\cite{malladi2024fine}.
% \hh{do we have a reference for this?}.
Efficiently training or fine-tuning a CL-based foundation model remains a great challenge.

\textbf{Better Multi-view Benchmark Datasets for CL Models.}
Currently, high-quality multi-view benchmark datasets are urgently needed for constructing multi-modal foundation models. While many large-scale text-attributed graphs are collected from social media, e-commerce platforms, and academic domains~\cite{DBLP:journals/corr/abs-2312-02783}, it's essential to acknowledge that real-world graphs span various domains, including finance, healthcare, transportation networks, and local infrastructure networks. Similarly, there is a high demand for large-scale text-image datasets to support the training of vision-language foundational models~\cite{wang2022diffusiondb}. Moreover, concerns have been raised regarding potential biases present in many benchmark datasets. Studies ~\cite{clark-etal-2019-dont, wan2023kelly, oba2023contextual, kotek2023gender} have highlighted the existence of contextual, demographic, and stereotypical biases within benchmark datasets used for large language models
% For instance, most large-scale text-attributed graphs are collected from social media, e-commerce platforms, and academic domains~\cite{DBLP:journals/corr/abs-2312-02783}. However, real-world graphs are ubiquitous, ranging from finance to health, from transportation networks to local infrastructure networks, etc. Similarly, large-scale text-image datasets are in high demand for training the vision language foundation model~\cite{wang2022diffusiondb}. In addition, some paper points out that potential bias exists in many benchmark datasets. For instance,~\cite{clark-etal-2019-dont, wan2023kelly, oba2023contextual, kotek2023gender} show the existence of contextual bias, demographics bias, stereotypical bias in the benchmark dataset for large language model.


\textbf{Trustworthy CL.}
% \hh{the connection between this paragraph and CL seems weak. for instance, we did not mention CL at all in this paragraph.}\lc{I have updated this future direction.}
Trustworthy machine learning refers to the development and deployment of machine learning models with a strong emphasis on interpretability, fairness, transparency, privacy, and robustness. While significant strides have been made in enhancing these aspects by CL-based regularization, inlcuding interpretability~\cite{DBLP:conf/emnlp/JacoviSRECG21, DBLP:journals/corr/abs-2005-12419}, fairness considerations~\cite{zhang2022fairness, zheng2023fairness, wang2022uncovering}, and out-of-distribution robustness~\cite{zheng2024multi, DBLP:conf/acl/MaSA21, DBLP:conf/nips/ZhangR22}, these efforts are still in their nascent stages, \eg, training models on small datasets or failing to consider the view or task heterogeneity.  Despite these early efforts, heterogeneous contrastive foundational models still encounter challenges related to interpretability, fairness, transparency, privacy, and robustness, which persist across multi-modal foundational models as well.

\textbf{Understanding Mechanisms Between CL Strategies and Downstream Tasks.}
As introduced in Section \ref{downstream_tasks}, we present various CL strategies for downstream tasks. However, it remains unclear which CL strategies are good for specific downstream tasks and how can we evaluate the quality of CL strategies. In addition, how different CL strategies compete and cooperate in downstream tasks is expected to be better evaluated and understood by the researchers. Moreover, how to combine CL with other self-supervised methods to further improve the performance of the foundation models deserves great attention.

% \by{
% 1. Connecting CL strategies and downstream tasks, which CL strategy is good for a specific downstream tasks? do we really need CL pre-training for some downstream tasks?\\
% 2. how to evaluate the quality of CL strategies? \\
% 3. further understand the CL strategies: 
% competition and cooperation between different strategies.\\
% 3. how to combine different datasets, how to address data bias, \\
% 4. continual learning for CL, \\
% 5. how to combine CL with other SSL methods, when to use CL and when to use other SSL methods, what are the advantages/disadvantages of CL over other SSL methods? \\
% 6. beyond 0/1 contrastive pairs, add confidences and weights for different pairs, more precise guidance: contrast words within sentences rather than the entire sentences. \\
% 7. active learning: can model actively identify which concepts are well-studied, which needs further clarification.
% }

\section{Conclusion}
This paper provides a thorough exploration of heterogeneous CL for foundation models. We first delve into the traditional CL methods, particularly in addressing view heterogeneity, and elucidate the application of CL techniques in training and fine-tuning multi-view foundation models. Subsequently, we discuss CL methods tailored to tackle task heterogeneity, including pretraining and downstream tasks, and illustrate how CL combines different tasks for various objectives. Finally, we outline potential future research directions in heterogeneous CL for foundation models.
% \section{Methodology}

\section{\methodname: Grounding free-texts to eventuality-centric knowledge graphs}
\label{sec:method}

% \subsubsection{Event extraction}
% \label{sec:event_extraction}
\begin{figure}[t]
\centering
\includegraphics[width=0.5\textwidth]{figs/pipeline.pdf}
\caption{An overview of \methodname.}
\label{fig:framework}
\end{figure}

% Given a piece of text $S={s_1, s_2, \cdots, s_n}$ with $n$ sentences, we 
% (1) extract events from texts, while preserving the co-reference information of the original text;
% (2) link (or ground) the events to the eventuality-centric KG $\mathcal{G}$; and 
% (3) leverage the grounded commonsense knowledge to facilitate narrative reasoning.

In this section, we present our proposed framework, \methodname.
An overview is presented in Figure \ref{fig:framework}.
To tackle the \textit{event representation} problem, we equip semantic parsing based event extraction ($\S$~\ref{sec:event_extraction}) with an event normalization module ($\S$~\ref{sec:event_normalization}) to separate events from contexts while preserving their arguments' co-reference information.
We solve the \textit{sparsity} problem by with a partial information extraction approach ($\S$~\ref{sec:event_abstraction}).
We empirically prove that these solutions largely alleviate the sparsity problem in $\S$~\ref{sec:ablation}. 
At the end of this section, we discuss grounding the partial events to KGs to obtain joint reasoning subgraphs in $\S$~\ref{sec:event_grounding}, and present both the GNN-based and LLM-based reasoning models in $\S$~\ref{sec:graph_model}. 

% The overall framework of our approach is shown in Figure~\ref{fig:framework}.


\subsection{Obtaining events}
The proposed event acquisition pipeline includes event extraction ($\S$~\ref{sec:event_extraction}), normalization ($\S$~\ref{sec:event_normalization}) and partial information extraction ($\S$~\ref{sec:event_abstraction}).

\subsubsection{Event extraction}
\label{sec:event_extraction}
As shown in the previous example, events do not naturally exist in free texts.
Instead, an event may share arguments with (e.g., \textbf{E1} and \textbf{E2}) or contain another event.
Therefore, a special extraction step is needed to separate events from their contexts.


In this work, we consider the semantic parsing based methods to extract events from their contexts.
For each piece of text $s=[s_1, s_2, \cdots, s_n]$ with $n$ sentences, we conduct semantic role labeling (SRL) on the text to extract a series of verb-centric events $\mathcal{P}=\{p_1, p_2, \cdots, p_m\}$, where each event $p_i=(verb^i, \mathcal{A}^i)$ has a trigger $verb^i$ and a set of arguments $\mathcal{A}^i$.
Each argument $a_j^i\in \mathcal{A}^i$ has  a semantic role $role(a_j^i)\in \{ARG_0, ARG_1, \cdots, ARG_M\}$\footnote{The annotation follows the PropBank \cite{palmer2005proposition} annotation guideline, where the numbered arguments in general correspond to the roles: $ARG_0$-agent; $ARG_1$-patient; $ARG_2$-instrument, benefactive, attribute; $ARG_3$-starting point, benefactive, attribute; $ARG_4$-ending point; $ARG_M$-modifier.}.
In addition, we define the operator $text(p_i)$ to obtain the text of $p_i$.


\subsubsection{Event normalization}
\label{sec:event_normalization}
It is noteworthy that the extracted events suffer from the loss of co-reference information.
For instance, here are three events extracted from a text:\footnote{For simplicity, we do not explicitly show verbs and arguments of the events. All the words in events are lemmatized in our pipeline, which is not shown in the examples.}
\begin{quote}
% \vspace{-6pt}
    (1) The general had some wine at a party. \\
    (2) He felt sleepy. \\
    (3) He said goodbye to them.
% \vspace{-6pt}
\end{quote}
where ``\textit{the general}'' and ``\textit{he}'' refer to the same person, while ``\textit{them}'' refers to another group of people.
A system would not be aware of this co-reference relationship without contexts.
This makes it difficult to reason on the extracted events.

Motivated by previous work \cite{sap2019atomic, fang2021discos} in constructing commonsense KGs, we replace tokens referring to people with special tokens\footnote{Specifically, the spans of personal words are detected by syntactic parsing and animacy classification. We then employ the co-reference information between these spans to normalize all spans that refer to persons.} (e.g., ``\texttt{[P0]},'' ``\texttt{[P0's]},'' ``\texttt{[P1]},'' where different numbers refer to different people).
For instance, ``\textit{the general}'' and ``\textit{he}'' are replaced by ``\texttt{[P0]},'' and ``\textit{them}'' is replaced by ``\texttt{[P1]}.''
Through this normalization process, the co-reference information is preserved:
\begin{quote}
% \vspace{-6pt}
    (1) \texttt{[P0]} had some wine at a party. \\
    (2) \texttt{[P0]} felt sleepy. \\
    (3) \texttt{[P0]} said goodbye to \texttt{[P1]}.
% \vspace{-6pt}
\end{quote}

In addition, the normalization helps reduce event sparsity by removing details in the personal words.
For instance, ``\textit{the general felt sleepy},'' ``\textit{Joe felt sleepy},'' and ``\textit{he felt sleepy}'' will all be normalized to ``\textit{\texttt{[P0]} felt sleepy}.''
This increases their probability of being successfully grounded to KGs.


\subsubsection{Partial information extraction}
\label{sec:event_abstraction}


The normalized events retain rich contextual details from the original texts, which are important for downstream reasoning processes.
However, the sparsity of events can pose challenges in event grounding, especially when most knowledge graphs (KGs) are far from complete \cite{min2013distant, xiong2019improving}. 
For example, a KG is more likely to include a general event like ``\textit{a person is drinking}'' than ``\textit{the general is drinking Sauvignon Blanc on the balcony},'' because the former is more general and likely to occur frequently.

Humans strongly depend on conceptual abstraction to identify similarities among seemingly different concepts and events, which enables generalizations to unfamiliar situations \cite{murphy2004big}.
For instance, we can learn that there is common abstraction between ``\textit{buy a ticket for `Avengers'}'' and ``\textit{buy a ticket for `Harry Potter'},'' and that how the commonality ``\textit{buy a ticket}'' relates to other events such as we should ``\textit{arrive at the theater in time}''.
With this concept in mind, we use a partial information extraction (PIE) phase to obtain partial events as a method of controllable abstraction.
% Research in psychology has shown that the human reasoning process heavily relies on conceptual abstraction \cite{murphy2004big}.
% For instance, we constantly learn to conceptually abstract events.
% This allows us to recognize the commonality between ``\textit{buy a ticket for `Avengers'}'' and ``\textit{buy a ticket for `Harry Potter'}.''
% Moreover, we learn the relationships between  ``\textit{buy a ticket}'' and other events.
% For example, we understand that we should ``\textit{arrive at the theater in time}'' after making the purchase.
% To address the sparsity problem, we apply multi-level abstraction to events. 
% Similar to the abstract thinking process of human beings, we gradually simplify the details of event arguments to obtain partial events.



The partial information extraction is based on the importance of event arguments in semantic role labeling~\cite{palmer2005proposition}.
For instance, $ARG_0$ and $ARG_1$ have the highest importance as they usually specify the subject and objects.
In contrast, the modifier argument $ARG_M$ express the least information, as it usually defines additional constraints of the predicate, such as when and where the event happens.
Specifically, we propose to drop the event arguments in the descending order of their importance.
For event $p=(verb, \mathcal{A})$ with $|\mathcal{A}|=k$, we iteratively drop its argument $a_j\in\mathcal{A}$, such that the roles of dropped arguments follow the order: (1) $ARG_M$\footnote{We do not drop the negation (e.g., \textit{not}, \textit{n't}, \textit{never}) and modals (e.g., \textit{will}, \textit{may}, \textit{can}) modifier arguments, since they are crucial building blocks in discourse as revealed in the linguistics study \cite{jordan1998power}.}, (2) $ARG_2$, $ARG_3$, $ARG_4$, (3) $ARG_1$ and (4) $ARG_0$.
The partial information extraction on event set $\mathcal{P}$ results in a new set of partial events $\mathcal{P}_{abs}$, where $\mathcal{P}_{abs}=\{\hat p_1, \hat p_2, \cdots, \hat p_m\}$.
Each element $\hat p_i=[p_i^0, p_i^1, \cdots]$ is a sequence of partial events correspond to event $p_i\in\mathcal{P}$ ($p_i^0=p_i$).


Below is an example of $\hat p$:
\begin{enumerate}
   \item[$p^0$] ARG0: \underline{\texttt{[P0]}} V: \underline{evacuated} ARG2: \underline{to a relative 's house} ARGM: \underline{last night}. 
    \item[$p^1$] ARG0: \underline{\texttt{[P0]}} V: \underline{evacuated} ARG2: \underline{to a relative 's house}. 
    \item[$p^2$] ARG0: \underline{\texttt{[P0]}} V: \underline{evacuated}.
    \item[$p^3$] V: \underline{evacuated}. 
\end{enumerate}
% \vspace{-5pt}

Each time an argument is dropped, the abstract level of the partial event increases.
Meanwhile, partial events on higher abstract level (e.g. $p^2$, $p^3$) are more likely to have been recorded in KGs, which alleviates the sparsity problem.
In $\S$~\ref{sec:ablation}, we empirically show that the partial information extraction improves the model performance by drastically increasing the hit rate of event grounding.





\subsection{Grounding to eventuality-centric KG} 
\label{sec:event_grounding}

In this section, we discuss the event grounding approach.
In $\S$~\ref{sec:event_matching}, we describe how to map events to eventuality-centric KGs to get the anchor events that have the closest semantic meaning.
In $\S$~\ref{sec:subgraph}, we describe how to retrieve grounded subgraphs based on the anchor events.


\subsubsection{Event matching}
\label{sec:event_matching}

Suppose we have an eventuality-centric KG $\mathcal{G}=(\mathcal{V}, \mathcal{E})$.
$\mathcal{V}$ and $\mathcal{E}$ are the node set and the edge set, respectively.
Each node $v_i \in \mathcal{V}$ is an event with a text attribute $text(v_i)$.
Then, for each event $p\in\mathcal{P}_{abs}$, our goal is to find the node $v\in\mathcal{V}$ (which we term as ``\textit{anchor event}'') that is the most similar to $p$:
\begin{equation}
    v = \arg \min\limits_{v\in\mathcal{V}} d(p, v),
\end{equation}
where $d(\cdot,\space\cdot)$ denotes the distance between events.


To define the similarity, previous work have explored \textit{token-level similarity} by computing the cosine distance for TF-IDF or BM25 vectors \cite{lv2020integrating}.
However, this method overlooks the semantics of events, and constantly fails by mapping to events with high inverse document frequency terms (e.g. ``\textit{\texttt{[P0's]} \underline{lung} gets punched}'' is matched with ``\textit{\texttt{[P0]} has \underline{lung} cancer}'').
Therefore, we turn to use \textit{semantic similarity} to match events.

Specifically, we encode event $p$ and $v$ with sentence transformers \cite{reimers2019sentence},\footnote{\url{https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2}} and compute $d(p,\space v)$ by the L2 distance:

\begin{equation}
    d(p, v) = ||\textrm{SBERT}(text(p)), \textrm{SBERT}(text(v))||_2.
\end{equation}

In practice, not every event can be successfully matched with the correct ones.
We empirically set a threshold $l$ over $d(p, v)$ to filter out the failed matches.\footnote{We sample 100 matching results and empirically set $l$=0.65 that filters out the most failed cases.}
As a result, partial events in $\mathcal{P}_{abs}$ are matched to their anchor events in $\mathcal{G}$, which we denote by $\mathcal{C}$.
$\mathcal{C}=\{\hat c_1, \hat c_2, \cdots, \hat c_m\}$, where each $\hat c_i$ is a sequence of anchor events matched from $\hat p_i$.


\subsubsection{Joint subgraph construction}
\label{sec:subgraph}

\noindent \textbf{Knowledge subgraph retrieval}
Based on the anchor events from the matching results in $\S$~\ref{sec:event_matching}, we aim to retrieve a subgraph $\mathcal{G}_{sub}=(\mathcal{V}_{sub}, \mathcal{E}_{sub})$ from $\mathcal{G}$.
Ideally, $\mathcal{G}_{sub}$ should contain the background world knowledge related to the reasoning, meanwhile cover minimal number of additional eventualities.
Finding such a subgraph is essentially trying to solve an NP-complete Steiner tree problem \cite{garey1977rectilinear, lin2019kagnet}, which is intractable.
As a workaround, we search for the shortest path within $\gamma$-hops between each event pair in $\{(v_a, v_b): v_a\in \hat c_i, v_b\in \hat c_j; \hat c_i, \hat c_j\in \mathcal{C}\}$.
For any path obtained, the nodes and edges along the path are added to $\mathcal{G}_{sub}$.

\noindent \textbf{Joint subgraph construction}
Based on $\mathcal{G}_{sub}$, we construct a joint knowledge enhanced subgraph $\mathcal{G}_{joint}=(\mathcal{V}_{joint}, \mathcal{E}_{joint})$ for reasoning.
Specifically, $\mathcal{G}_{joint}$ includes all the nodes and edges in $\mathcal{G}_{sub}$.
In addition, we add the context events in $\mathcal{P}$ as nodes to $\mathcal{G}_{joint}$, where their grounding relation to anchor events in $\mathcal{C}$ as well as the context relation (between the previous and latter events in the order that they appear in context) are added as edges.

\subsection{Graph reasoning models}
\label{sec:graph_model}

The retrieved subgraphs are then used for reasoning using either a GNN-based reasoning model or an LLM-based reasoning model.

\noindent \textbf{GNN-based reasoning model.}
We first encode the text $s$ and node $v\in\mathcal{V}_{joint}$ using the language model representation:
\begin{equation}
\begin{split}
    \textbf{v} & = f_{\small{\textsc{LM}}}(text(v)), \\
    \textbf{s} & = f_{\small{\textsc{LM}}}(s).
\end{split}
\end{equation}
Then, we employ a GNN module to perform reasoning on the joint subgraph $\mathcal{G}_{joint}$.
We choose the relational graph convolutional networks (RGCN) \cite{schlichtkrull2018modeling} so that the relational information in $\mathcal{G}_{joint}$ can be well modeled.
Specifically, for each layer $l$ in an $L$-layer GNN, the representation $\textbf{h}_i^{(l)}$ of node $i\in\mathcal{V}_{joint}$ is updated by
\begin{equation}
    \mathbf{h}_{i}^{(l+1)} = \sigma \Big(\sum\limits_{r\in\mathcal{R}}\sum\limits_{j\in\mathcal{N}_r(i)}\frac{1}{|\mathcal{N}_r(i)|}\mathbf{W}_r\cdot \mathbf{h}_{j}^{(l)}\Big),
\end{equation}
where $\mathcal{R}$ is the set of edge types in $\mathcal{E}_{joint}$, $\mathcal{N}_r(i)$ denotes the neighborhood with relation $r$ of node $i$, and $\sigma (\cdot)$ is an non-linear activation.
Then, we obtain the vector representation for $\mathcal{G}_{joint}$ by pooling the hidden node embeddings from the last layer
\begin{equation}
    \mathbf{g} = \textrm{Pooling}(\{\mathbf{h}_{i}^{L}: i\in\mathcal{V}_{joint}\}).
\end{equation}
The final prediction comes from 
\begin{equation}
    p(s) \propto \textbf{MLP} (\mathbf{s}+\mathbf{g}),
\end{equation}
where $\textbf{MLP}$ means a multi-layer perceptron module to predict the probability of the output.

\vspace{0.05\linewidth}

\noindent \textbf{LLM-based reasoning model.}
We also explored fusing the eventuality knowledge subgraph $\mathcal{G}_{joint}$ into LLMs.
Since LLMs only receive sequence inputs, we conduct sequentialization on subgraphs in a format similar to \cite{madaan-yang-2021-neural, sakaguchi-etal-2021-proscript-partially}.
Using a transformation function $t(\cdot)$, a subgraph $\mathcal{G}_{joint}$ is transformed into a piece of text $s_{\mathcal{G}_{joint}}$ ($s_{\mathcal{G}_{joint}}=t(\mathcal{G}_{joint})$), which is then fed into LLM as part of the prompts.
We discuss variations of $t(\cdot)$ and other details in $\S$~\ref{sec:exp-setup}.

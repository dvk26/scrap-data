@article{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}
@article{lauscher2020common,
  title={Common sense or world knowledge? investigating adapter-based knowledge injection into pretrained transformers},
  author={Lauscher, Anne and Majewska, Olga and Ribeiro, Leonardo FR and Gurevych, Iryna and Rozanov, Nikolai and Glava{\v{s}}, Goran},
  journal={arXiv preprint arXiv:2005.11787},
  year={2020}
}
@inproceedings{martino2023knowledge,
  title={Knowledge injection to counter large language model (LLM) hallucination},
  author={Martino, Ariana and Iannelli, Michael and Truong, Coleen},
  booktitle={European Semantic Web Conference},
  pages={182--185},
  year={2023},
  organization={Springer}
}
@article{fan2020enhanced,
  title={An enhanced knowledge injection model for commonsense generation},
  author={Fan, Zhihao and Gong, Yeyun and Wei, Zhongyu and Wang, Siyuan and Huang, Yameng and Jiao, Jian and Huang, Xuanjing and Duan, Nan and Zhang, Ruofei},
  journal={arXiv preprint arXiv:2012.00366},
  year={2020}
}
@inproceedings{NEURIPS2020_6b493230,
 author = {Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K\"{u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt\"{a}schel, Tim and Riedel, Sebastian and Kiela, Douwe},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {9459--9474},
 publisher = {Curran Associates, Inc.},
 title = {Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks},
 url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/6b493230205f780e1bc26945df7481e5-Paper.pdf},
 volume = {33},
 year = {2020}
}
@misc{schulman2017proximal,
      title={Proximal Policy Optimization Algorithms}, 
      author={John Schulman and Filip Wolski and Prafulla Dhariwal and Alec Radford and Oleg Klimov},
      year={2017},
      eprint={1707.06347},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{song2016better,
      title={Two are Better than One: An Ensemble of Retrieval- and Generation-Based Dialog Systems}, 
      author={Yiping Song and Rui Yan and Xiang Li and Dongyan Zhao and Ming Zhang},
      year={2016},
      eprint={1610.07149},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@inproceedings{Chen_2022, 
   series={WWW ’22},
   title={KnowPrompt: Knowledge-aware Prompt-tuning with Synergistic Optimization for Relation Extraction},
   url={http://dx.doi.org/10.1145/3485447.3511998},
   DOI={10.1145/3485447.3511998},
   booktitle={Proceedings of the ACM Web Conference 2022},
   publisher={ACM},
   author={Chen, Xiang and Zhang, Ningyu and Xie, Xin and Deng, Shumin and Yao, Yunzhi and Tan, Chuanqi and Huang, Fei and Si, Luo and Chen, Huajun},
   year={2022},
   month=apr, collection={WWW ’22}
}
@misc{wang2020kadapter,
      title={K-Adapter: Infusing Knowledge into Pre-Trained Models with Adapters}, 
      author={Ruize Wang and Duyu Tang and Nan Duan and Zhongyu Wei and Xuanjing Huang and Jianshu ji and Guihong Cao and Daxin Jiang and Ming Zhou},
      year={2020},
      eprint={2002.01808},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@incollection{MCCLOSKEY1989109,
title = {Catastrophic Interference in Connectionist Networks: The Sequential Learning Problem},
editor = {Gordon H. Bower},
series = {Psychology of Learning and Motivation},
publisher = {Academic Press},
volume = {24},
pages = {109-165},
year = {1989},
issn = {0079-7421},
doi = {https://doi.org/10.1016/S0079-7421(08)60536-8},
url = {https://www.sciencedirect.com/science/article/pii/S0079742108605368},
author = {Michael McCloskey and Neal J. Cohen},
abstract = {Publisher Summary
Connectionist networks in which information is stored in weights on connections among simple processing units have attracted considerable interest in cognitive science. Much of the interest centers around two characteristics of these networks. First, the weights on connections between units need not be prewired by the model builder but rather may be established through training in which items to be learned are presented repeatedly to the network and the connection weights are adjusted in small increments according to a learning algorithm. Second, the networks may represent information in a distributed fashion. This chapter discusses the catastrophic interference in connectionist networks. Distributed representations established through the application of learning algorithms have several properties that are claimed to be desirable from the standpoint of modeling human cognition. These properties include content-addressable memory and so-called automatic generalization in which a network trained on a set of items responds correctly to other untrained items within the same domain. New learning may interfere catastrophically with old learning when networks are trained sequentially. The analysis of the causes of interference implies that at least some interference will occur whenever new learning may alter weights involved in representing old learning, and the simulation results demonstrate only that interference is catastrophic in some specific networks.}
}
@inproceedings{xu-etal-2023-kilm,
    title = "{KILM}: Knowledge Injection into Encoder-Decoder Language Models",
    author = "Xu, Yan  and
      Namazifar, Mahdi  and
      Hazarika, Devamanyu  and
      Padmakumar, Aishwarya  and
      Liu, Yang  and
      Hakkani-Tur, Dilek",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.275",
    doi = "10.18653/v1/2023.acl-long.275",
    pages = "5013--5035",
    abstract = "Large pre-trained language models (PLMs) have been shown to retain implicit knowledge within their parameters. To enhance this implicit knowledge, we propose Knowledge Injection into Language Models (KILM), a novel approach that injects entity-related knowledge into encoder-decoder PLMs, via a generative knowledge infilling objective through continued pre-training. This is done without architectural modifications to the PLMs or adding additional parameters. Experimental results over a suite of knowledge-intensive tasks spanning numerous datasets show that KILM enables models to retain more knowledge and hallucinate less while preserving their original performance on general NLU and NLG tasks. KILM also demonstrates improved zero-shot performances on tasks such as entity disambiguation, outperforming state-of-the-art models having 30x more parameters.",
}
@misc{tian2023finetuning,
      title={Fine-tuning Language Models for Factuality}, 
      author={Katherine Tian and Eric Mitchell and Huaxiu Yao and Christopher D. Manning and Chelsea Finn},
      year={2023},
      eprint={2311.08401},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{rafailov2023direct,
      title={Direct Preference Optimization: Your Language Model is Secretly a Reward Model}, 
      author={Rafael Rafailov and Archit Sharma and Eric Mitchell and Stefano Ermon and Christopher D. Manning and Chelsea Finn},
      year={2023},
      eprint={2305.18290},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{ovadia2024finetuning,
      title={Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs}, 
      author={Oded Ovadia and Menachem Brief and Moshik Mishaeli and Oren Elisha},
      year={2024},
      eprint={2312.05934},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}
@misc{bai2022constitutional,
      title={Constitutional AI: Harmlessness from AI Feedback}, 
      author={Yuntao Bai and Saurav Kadavath and Sandipan Kundu and Amanda Askell and Jackson Kernion and Andy Jones and Anna Chen and Anna Goldie and Azalia Mirhoseini and Cameron McKinnon and Carol Chen and Catherine Olsson and Christopher Olah and Danny Hernandez and Dawn Drain and Deep Ganguli and Dustin Li and Eli Tran-Johnson and Ethan Perez and Jamie Kerr and Jared Mueller and Jeffrey Ladish and Joshua Landau and Kamal Ndousse and Kamile Lukosuite and Liane Lovitt and Michael Sellitto and Nelson Elhage and Nicholas Schiefer and Noemi Mercado and Nova DasSarma and Robert Lasenby and Robin Larson and Sam Ringer and Scott Johnston and Shauna Kravec and Sheer El Showk and Stanislav Fort and Tamera Lanham and Timothy Telleen-Lawton and Tom Conerly and Tom Henighan and Tristan Hume and Samuel R. Bowman and Zac Hatfield-Dodds and Ben Mann and Dario Amodei and Nicholas Joseph and Sam McCandlish and Tom Brown and Jared Kaplan},
      year={2022},
      eprint={2212.08073},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{enwiki:1214162630,
    author = "{Wikipedia contributors}",
    title = "2023 FIFA Women's World Cup --- {Wikipedia}{,} The Free Encyclopedia",
    year = "2024",
    url = "https://en.wikipedia.org/w/index.php?title=2023_FIFA_Women%27s_World_Cup&oldid=1214162630",
    note = "[Online; accessed 27-March-2024]"
}
@misc{enwiki:1213361100,
    author = "{Wikipedia contributors}",
    title = "2023 Cricket World Cup --- {Wikipedia}{,} The Free Encyclopedia",
    year = "2024",
    url = "https://en.wikipedia.org/w/index.php?title=2023_Cricket_World_Cup&oldid=1213361100",
    note = "[Online; accessed 27-March-2024]"
}
@misc{enwiki:1215541265,
    author = "{Wikipedia contributors}",
    title = "Super Bowl LVII --- {Wikipedia}{,} The Free Encyclopedia",
    year = "2024",
    url = "https://en.wikipedia.org/w/index.php?title=Super_Bowl_LVII&oldid=1215541265",
    note = "[Online; accessed 27-March-2024]"
}
@misc{enwiki:1213024529,
    author = "{Wikipedia contributors}",
    title = "2023 Masters Tournament --- {Wikipedia}{,} The Free Encyclopedia",
    year = "2024",
    url = "https://en.wikipedia.org/w/index.php?title=2023_Masters_Tournament&oldid=1213024529",
    note = "[Online; accessed 27-March-2024]"
}
@misc{enwiki:1215798602,
    author = "{Wikipedia contributors}",
    title = "2023 NCAA Division I men's basketball tournament --- {Wikipedia}{,} The Free Encyclopedia",
    year = "2024",
    url = "https://en.wikipedia.org/w/index.php?title=2023_NCAA_Division_I_men%27s_basketball_tournament&oldid=1215798602",
    note = "[Online; accessed 27-March-2024]"
}
@misc{enwiki:1216022372,
    author = "{Wikipedia contributors}",
    title = "2018 FIFA World Cup --- {Wikipedia}{,} The Free Encyclopedia",
    year = "2024",
    url = "https://en.wikipedia.org/w/index.php?title=2018_FIFA_World_Cup&oldid=1216022372",
    note = "[Online; accessed 27-March-2024]"
}
@misc{msftaoaimodeldocs,
      title={Azure OpenAI Service models}, 
      year={2024},
      note = "[Online; accessed 27-March-2024]",
      url = "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-preview",
}
@misc{msftvectorsearchdocs,
      title={Azure OpenAI On Your Data}, 
      year={2024},
      note = "[Online; accessed 27-March-2024]",
      url = "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/use-your-data?tabs=ai-search",
}
@misc{balaguer2024rag,
      title={RAG vs Fine-tuning: Pipelines, Tradeoffs, and a Case Study on Agriculture}, 
      author={Angels Balaguer and Vinamra Benara and Renato Luiz de Freitas Cunha and Roberto de M. Estevão Filho and Todd Hendry and Daniel Holstein and Jennifer Marsman and Nick Mecklenburg and Sara Malvar and Leonardo O. Nunes and Rafael Padilha and Morris Sharp and Bruno Silva and Swati Sharma and Vijay Aski and Ranveer Chandra},
      year={2024},
      eprint={2401.08406},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@article{openai2024gpt4,  
    author = {OpenAI},  
    title = {GPT-4 Technical Report},  
    year = {2023},  
    journal = {arXiv preprint arXiv:2303.08774},  
    url = {https://doi.org/10.48550/arXiv.2303.08774}  
}  
% ****** Start of file apssamp.tex ******
%
%   This file is part of the APS files in the REVTeX 4.2 distribution.
%   Version 4.2a of REVTeX, December 2014
%
%   Copyright (c) 2014 The American Physical Society.
%
%   See the REVTeX 4 README file for restrictions and more information.
%
% TeX'ing this file requires that you have AMS-LaTeX 2.0 installed
% as well as the rest of the prerequisites for REVTeX 4.2
%
% See the REVTeX 4 README file
% It also requires running BibTeX. The commands are as follows:
%
%  1)  latex apssamp.tex
%  2)  bibtex apssamp
%  3)  latex apssamp.tex
%  4)  latex apssamp.tex
%
\documentclass[amsmath,amssymb,aps]{revtex4-2}

\usepackage{filecontents}
\usepackage{graphicx}
\usepackage{float}
\usepackage{subcaption}
\usepackage{physics}
\usepackage{hyperref}
\usepackage{color}
\usepackage{xr}

\definecolor{Black}{rgb}{0.00, 0.00, 0.00}
\definecolor{Blue}{rgb}{0.00, 0.00, 0.80}
\definecolor{Red}{rgb}{0.80, 0.00, 0.00}
\definecolor{Green}{rgb}{0.00, 0.50, 0.00}
\definecolor{Purp}{rgb}{0.50, 0.00, 0.50}
\newcommand{\red}{\color{Red}}
\newcommand{\blue}{\color{Blue}}
\newcommand{\green}{\color{Green}}
\newcommand{\purp}{\color{Purp}}

\hypersetup{
    colorlinks=true,       % false: boxed links; true: colored links
    linkcolor=red,          % color of internal links (change box color with linkbordercolor)
    citecolor=blue,        % color of links to bibliography
    filecolor=magenta,      % color of file links
    urlcolor=cyan           % color of external links
}

\captionsetup{%
    justification=Justified,%
}

\newcommand*{\addFileDependency}[1]{% argument=file name and extension
\typeout{(#1)}% latexmk will find this if $recorder=0
% however, in that case, it will ignore #1 if it is a .aux or 
% .pdf file etc and it exists! If it doesn't exist, it will appear 
% in the list of dependents regardless)
%
% Write the following if you want it to appear in \listfiles 
% --- although not really necessary and latexmk doesn't use this
%
%\@addtofilelist{#1}
%
% latexmk will find this message if #1 doesn't exist (yet)
\IfFileExists{#1}{}{\typeout{No file #1.}}
}\makeatother

\newcommand*{\myexternaldocument}[1]{%
\externaldocument{#1}%
\addFileDependency{#1.tex}%
\addFileDependency{#1.aux}%
}
%------------End of helper code--------------

% put all the external documents here!
\myexternaldocument{main}

\makeatletter

% Add S to equation/figure numbers
\renewcommand{\theequation}{S\arabic{equation}}
\renewcommand{\thefigure}{S\arabic{figure}}

\begin{document}

\title{Minimizing the Profligacy of Searches with Reset\\[1ex] Supplemental Material}

\author{John C. Sunil}
\author{Richard A. Blythe}
\author{Martin R. Evans}
\affiliation{SUPA, School of Physics and Astronomy, University of Edinburgh, Peter Guthrie Tait Road, Edinburgh EH9 3FD, UK}

\author{Satya N. Majumdar}
\affiliation{Universit{\'e} Paris-Saclay, CNRS, LPTMS, 91405, Orsay, France}

\date{\today}

\maketitle

This Supplemental Material details the calculations of the mean cost (Section~\ref{sec:cost}) and the success probability (Section~\ref{sec:sprob}) in diffusion with resetting. Section~\ref{sec:landau} sets out the Landau-like expansion of the profligacy and the procedure for determining where phase boundaries lie. Finally, we briefly expand in Section~\ref{sec:prof} on the interpretation of the profligacy function introduced in the main text as it applies to the case of predetermined search strategies.

\section{Derivation of the mean cost}
\label{sec:cost}

The key quantity that is required to determine the mean total cost incurred in a diffusive resetting process is $\Omega_r(C,t_f)$, the statistical weight of trajectories  that start at the origin at $t=0$, return to the origin as a Poisson process at rate $r$, end at a predetermined time $t=t_f$ and incur a total cost $C$. These statistical weights will differ in the ensemble where the endpoint of the trajectory is free (as in Resetting Brownian Motion, RBM) or constrained to lie at the origin (as in a Resetting Brownian Bridge, RBB). Once this quantity is known, we can determine the mean cost over such trajectories as
\begin{equation}
    \expval{C} = \frac{\int{\rm d}C\, C\, \Omega_r(C,t_f)}{\int{\rm d}C\,\Omega_r(C,t_f)} \;.
    \label{expC}
\end{equation}

An explicit expression for $\Omega_r(C,t_f)$ is obtained from a renewal equation. The idea is to consider the evolution from the start of the process until either one of two things happens. The first possibility is that the particle resets for the first time at some time $0\le t\le t_f$, after which the entire process restarts from the origin, with the remainder of the trajectory lasting a time $t-t_f$ and incurring a cost $C-c(x)$, where $c(x)\ge0$ is the cost of resetting from the point $x$ to the origin.  In this case, the particle resets with probability ${\rm e}^{-rt}r{\rm d}t$ in the interval $[t,t+{\rm d} t]$, and is distributed over space as $G(x;t)$ which is the Green function for diffusion,
\begin{equation}
    G(x;t) = \frac{1}{\sqrt{4\pi D t}}e^{-\frac{(x-x_0)^2}{4 D t}} \label{G0}
\end{equation}
where $D$ is the diffusion constant. The second possibility is the particle reaches the point $x$ at time $t_f$ without resetting. This event arises with probability ${\rm e}^{-rt}$, incurs zero cost and we allow only those endpoints $x$ that fall within the set $E$. For the case of RBM, $E$ is the entire real line, whereas for RBB, $E$ is the origin.

Expressing these two possibilities as a renewal equation, we find
\begin{equation}
    \Omega_r(C,t_f) = \int_0^{t_f} {\rm d} t\, r{\rm e}^{-r t} \int_{-\infty}^\infty {\rm d} x\, G(x;t)
    \Omega_r(C-c(x),t_f-t) + {\rm e}^{-r t} \delta(C) \int_E {\rm d}x \, G(x;t_f) \;.\label{renew1} 
\end{equation}
The first term is a convolution and thus the recursion can be solved by introducing the double Laplace transform
\begin{equation}
\widetilde{\Omega}_r(p,s) = \int_0^\infty {\rm d} C\, {\rm e}^{-pC} \int_0^\infty {\rm d} t_f\, e^{-st_f} \Omega_r(C,t_f)\;.
\end{equation}

\paragraph*{Note on notation} Here we have used $\widetilde{\Omega}_r(N,p|x_0,s)$ to indicate a double Laplace transform. We will also use a tilde symbol to denote single Laplace transforms of a single time variable, e.g. $\widetilde{G}(x;s)$, below. The arguments of the function should  make  clear the number of Laplace variables. In certain places, for convenience, we will use ${\mathcal L}_{t\to s}$ to indicate Laplace transform to Laplace variable $s$ and ${\mathcal L}^{-1}_{s\to t}$ to indicate Laplace inversion to the time domain.
\medskip

Laplace transforming (\ref{renew1}) with respect to both arguments and rearranging, we find
\begin{equation}
    \widetilde{\Omega}_r(p,s) = \frac{\widetilde{K}(r+s)}{1 - r \widetilde{W}(p,r+s)}
\end{equation}
where
\begin{align}
    \label{K}
    \widetilde{K}(s) &=  \int_E {\rm d}x \, \int_{0}^{\infty}{\rm d}t_f\,{\rm e}^{-s t_f} G(x;t_f) =  \int_E {\rm d}x \, \widetilde{G}(x;s) \\
    \widetilde{W}(p,s) &= \int_{-\infty}^\infty {\rm d} x\, {\rm e}^{-p c(x)} \int_{0}^{\infty}{\rm d}t\, {\rm e}^{- s t} G(x;t) = \int_{-\infty}^\infty {\rm d} x\, {\rm e}^{-p c(x)} \widetilde{G}(x;s)
\end{align}
and we have from (\ref{G0}) that
\begin{equation}
        \widetilde{G}(x,s) = \frac{1}{2\sqrt{Ds}}e^{-\sqrt{\frac{s}{D}}\abs{x}} \;.
\end{equation}
We see that the function $\widetilde{K}(s)$ is determined by the constraint placed on the endpoint of the trajectory, and that $\widetilde{W}(p,s)$ depends on the functional form of the cost. Once these functions have been determined for the cases of interest, we can obtain the mean cost as a function of $t_f$ from (\ref{expC}) via
\begin{equation}
    \expval{C} = \frac{ {\mathcal L}^{-1}_{s\to t_f} \{ - \partial_p \widetilde{\Omega}_r(p,s) |_{p\to 0} \}}{ {\mathcal L}^{-1}_{s\to t_f} \{ \widetilde{\Omega}_r(p,s)|_{p\to 0} \} } \;.
    \label{Cinv}
\end{equation}
Taking the limit $p\to0$, we find that the functions to be inverted to obtain the numerator and denominator, respectively, are
\begin{align}
\label{numinv}
\left. - \partial_p \widetilde{\Omega}_r(p,s) \right|_{p\to 0} &= \frac{r(r+s)^2}{s^2} \widetilde{K}(r+s) \int_{-\infty}^\infty {\rm d}x\, c(x) \widetilde{G}(x;r+s) \\
\left. \widetilde{\Omega}_r(p,s) \right|_{p\to 0} &= \frac{r+s}{s} \widetilde{K}(r+s) \;.
\end{align}

\subsection{Resetting Brownian Motion (RBM)}

For the case of RBM, the trajectory endpoint is unconstrained, and the integral in (\ref{K}) is over all $x$. For any properly normalized distribution of endpoints we then have $\widetilde{K}(s) = \frac{1}{s}$ and the denominator in (\ref{Cinv}) is unity. It thus remains to compute the numerator by inverting (\ref{numinv}) for the cost function of interest. In the main text we consider power-law cost functions,
\begin{equation}
    c(x) = 2^{n/2} \abs{y}^n \quad\mbox{where}\quad y = \frac{x}{\sqrt{2Dt_f}} \;,
\label{costn}
\end{equation}
specifically the linear and quadratic cases, $n=1$ and $n=2$. Substituting into (\ref{numinv}) yields
\begin{equation}
\label{Crbm}
    \expval{C}_n^{\rm RBM} = \frac{\Gamma(n+1)}{t_f^{n/2}} {\mathcal L}^{-1}_{s\to t_f} \left\{ \frac{r}{s^2} \frac{1}{(r+s)^{n/2}} \right\} = \frac{\Gamma(n+1)}{R^{n/2}} \frac{R \gamma(\frac{n}{2},R) - \gamma(\frac{n}{2}+1, R)}{\Gamma(\frac{n}{2})}
\end{equation}
where $R=r t_f$ is the dimensionless resetting rate, and $\gamma(s,x)$ is the lower incomplete Gamma function,
\begin{equation}
    \gamma(s,x) = \int_0^x {\rm d} u\, u^{s-1} {\rm e}^{-u} \;.
\end{equation}
Note that this result is obtained by recognising the Laplace transform in (\ref{Crbm}) as the convolution of $t$ with $\frac{1}{\Gamma(n/2)} t^{n/2-1} {\rm e}^{-r t}$, evaluated at $t_f$. Note further that $\langle C \rangle_0^{\rm RBM} = R$ and that for the special cases $n=1$ (`lin') and $n=2$ (`quad') considered in the main text, we have
\begin{align}
    \label{Crbmlin}
    \expval{C}^{\rm RBM}_{\rm lin} &= \frac{{\rm e}^{-R}}{\sqrt{\pi}} + 
    \frac{(2R-1)\erf\left(\sqrt{R}\right)}{2 \sqrt{R}} \\
    \label{Crbmquad}
    \expval{C}^{\rm RBM}_{\rm quad} &= \frac{2 \left(R+{\rm e}^{-R}-1\right)}{R} \;,
\end{align}
where we have used
\begin{equation}
\Gamma({\textstyle\frac{1}{2}}) = \sqrt{\pi} \;,\quad
\gamma({\textstyle\frac{1}{2}}, x) = \sqrt{\pi} \erf(\sqrt{x}) \quad\mbox{and}\quad 
\gamma(1, x) = 1 - {\rm e}^{-x}
\end{equation}
along with the recursion relation
\begin{equation}
    \gamma(s+1, x) = s \gamma(s, x) - x^s {\rm e}^{-x} \;.
\end{equation}

\subsection{Resetting Brownian Bridge (RBB)}

For the RBB, the calculation is a little more complex due to the constraint on the trajectory endpoint. Taking $E$ to comprise just the point at the origin in (\ref{K}) we now have $\widetilde{K}(s) = \frac{1}{2\sqrt{Ds}}$ and the denominator of (\ref{Cinv}) takes the form
\begin{equation}
\label{norm_time}
{\mathcal L}^{-1}_{s\to t_f} \{ \widetilde{\Omega}_r(p,s)|_{p\to 0} \} = \frac{1}{2\sqrt{D}} {\mathcal L}^{-1}_{s\to t_f} \left\{ \left(1+\frac{r}{s}\right) \frac{1}{\sqrt{r+s}} \right\} = 
\frac{{\rm e}^{-r t_f} + \sqrt{\pi r t_f} \erf(\sqrt{r t_f})}{2\sqrt{\pi D t_f}} \;.
\end{equation}
Again, the inversion can be performed by recognising as a convolution.

Turning now to the numerator, we find for $c(x)$ given by (\ref{costn}) that
\begin{equation}
    {\mathcal L}^{-1}_{s\to t_f} \{ - \partial_p \widetilde{\Omega}_r(p,s) |_{p\to 0} \} = \frac{1}{2\sqrt{D}} \frac{\Gamma(n+1)}{t_f^{n/2}}  {\mathcal L}^{-1}_{s\to t_f} \left\{ \frac{r}{s^2} \frac{1}{(r+s)^{(n-1)/2}} \right\} \;.
\end{equation}
Comparing with (\ref{Crbm}) we see that
\begin{equation}
    {\mathcal L}^{-1}_{s\to t_f} \{ - \partial_p \widetilde{\Omega}_r(p,s) |_{p\to 0} \} = \frac{n}{2\sqrt{Dt_f}} \expval{C}_{n-1}^{\rm RBM}
\end{equation}
and by dividing by the denominator (\ref{norm_time}) we find
\begin{equation}
    \expval{C}_{n}^{\rm RBB} = \frac{n\sqrt{\pi} \expval{C}_{n-1}^{\rm RBM}}{{\rm e}^{-R} + \sqrt{\pi R} \erf(\sqrt{R})} \;,
\end{equation}
recalling that $R=rt_f$. For the special cases $n=1$ and $n=2$ we have
\begin{align}
    \label{Crbblin}
    \expval{C}^{\rm RBB}_{\rm lin} &= \frac{\sqrt{\pi}R}{{\rm e}^{-R}+\sqrt{\pi R} \erf(\sqrt{R})} \\
    \label{Crbbquad}
    \expval{C}^{\rm RBB}_{\rm quad} &=2 - \sqrt{\frac{\pi}{R}} \frac{\erf (\sqrt{R})}{{\rm e}^{-R}+\sqrt{\pi R}\erf(\sqrt{R})} \;.
\end{align}

\medskip

We compare the functional forms of the mean cost between the two ensembles in Fig.~\ref{fig:costs}. Fig.~\ref{fig:linear_costs} shows how the mean linear cost behaves with $R$, and is seen to increase indefinitely as $R \to \infty$ as  $\sqrt{R}$. Corresponding plots for the mean quadratic cost are in Fig. \ref{fig:quad_costs}. Unlike the case for the linear cost, the mean total quadratic cost saturates as $R \to \infty$.

\begin{figure}[tb]

\centering
    \begin{subfigure}{.45\textwidth}
		\centering
	    \includegraphics[width=\linewidth]{Linear_cost_RBM_RBB.pdf} 
		\caption{}
        \label{fig:linear_costs}
	\end{subfigure}
 %
    \begin{subfigure}{.45\textwidth}
		\centering
	    \includegraphics[width=\linewidth]{Quadratic_cost_RBM_RBB.pdf} 
		\caption{}
        \label{fig:quad_costs}
	\end{subfigure}
   %
 \caption{Comparison of mean total cost $\langle C \rangle$ for (a) linear cost and (b) quadratic cost per reset for RBM and RBB. It can be seen that the costs increase monotonically for both the cases. This is consistent with the intuition that more frequent resets will incur a higher cost. Although in the case of a linear cost the mean cost increases indefinitely with $R$ we find that in the case of  a quadratic cost the mean cost saturates as $R\to \infty$.}
 \label{fig:costs}
\end{figure}

\section{Derivation of Success Probabilities}
\label{sec:sprob}

\subsection{Resetting Brownian Motion (RBM)}

For a Resetting Brownian Motion, the probability of reaching a target at position $m$ by time $t_f$ can be obtained from the target's survival probability which was given as Eq.~(6) in \cite{EM11a}. Noting that the target surviving corresponds to an unsuccessful search, we find that the success probability is given by the inverse Laplace transform
\begin{align}
    P_s^{\text{RBM}} = \int_{\Gamma} \frac{{\rm d}s}{2\pi i}{\rm e}^{st_f} \frac{1}{s} \frac{r+s}{r+s{\rm e}^{\sqrt{\frac{r+s}{D}}m}}\;.
\end{align}
where $\Gamma$ is the Bromwich contour. By introducing rescaled variables $u = st_f, R = rt_f$ and $M = \frac{m}{\sqrt{2Dt_f}}$, we obtain the form presented in the main text,
\begin{align}
    \label{Prbm}
    P_s^{\text{RBM}} = \int_{\Gamma} \frac{{\rm d}u}{2\pi i}e^{u} \frac{1}{u} \frac{R+u}{R+u {\rm e}^{M\sqrt{2}\sqrt{u+R}}}\;.
\end{align}

\subsection{Resetting Brownian Bridge (RBB)}

The success probability for a Resetting Brownian Bridge is provided as Eq.~(54) in the Supplemental Material of Ref.~\cite{BMS22}. In the notation of the present work, this reads
\begin{align}
    \label{Prbb}
    P_s^{\text{RBB}} = \phi(R) \int_\Gamma \frac{d{\rm u}}{2\pi i}{\rm e}^u \frac{\sqrt{u+R}}{u} \frac{R+u {\rm e}^{-M\sqrt{2}\sqrt{u+R}}}{R+u {\rm e}^{M\sqrt{2}\sqrt{u+R}}} 
    \quad\mbox{where}\quad 
    \phi(R) = \frac{\sqrt{\pi}}{e^{-R}+\sqrt{\pi R}\erf\left( \sqrt{R} \right)}\;.    
\end{align}

\medskip

We can plot the success probabilities (\ref{Prbm}) and (\ref{Prbb}) by performing the inverse Laplace transforms numerically \cite{AW06}. In Figure~\ref{fig:ps_m_1}, we plot the two functions obtained at fixed $M=1$. For RBM, we find that the success probability decreases monotonically with $R$, whilst for RBB, the function is peaked at some nonzero resetting rate $R$. When $M$ is reduced to $\frac{1}{2}$, Figure~\ref{fig:ps_m_0_5}, we find that both functions are peaked.

\begin{figure}[tb]
\centering
    \begin{subfigure}{.45\textwidth}
		\centering
	    \includegraphics[width=\linewidth]{Ps_m_1_RBM_RBB.pdf} 
		\caption{}
        \label{fig:ps_m_1}
	\end{subfigure}
 %
    \begin{subfigure}{.45\textwidth}
		\centering
	    \includegraphics[width=\linewidth]{Ps_m_0_5_RBM_RBB.pdf} 
		\caption{}
        \label{fig:ps_m_0_5}
	\end{subfigure}
   %
 \caption{Comparison of probability of finding the target $(P_{\rm s})$ as a function $R$ for (a) $M = 1.0$ and (b) $M = 0.5$. For RBM (purple), $P_{\rm s}$ can initially be a decreasing of increasing function function depending on the value of $M$, whereas for RBB (green) $P_{\rm s}$ always increases initially with resetting, reaches a maximum then decreases for large $R$.}
 \label{fig:ps}
\end{figure}

\section{Landau-like expansion for Profligacy ($\xi$)}
\label{sec:landau}

To gain deeper insight into the nature of the transitions observed in the main text, we make  a Landau-like expansion of the profligacy \eqref{profligacy}
\begin{align}
    \xi = \expval{C} - \lambda \ln{P_{\text{s}}}\,
\end{align}
in powers of $R$, valid for small values of $R$, which we define as
\begin{align}
    \xi = a_0 + a_1 R + a_2 \frac{R^2}{2} + a_3 \frac{R^3}{6} + a_4 \frac{R^4}{24} + \ldots\;, \label{landau_expansion_S}
\end{align}
where $a_i = a_i(\lambda,M)$. Due to the system not possessing an $R \to -R$ symmetry, we have to include all terms of the expansion.  The expansion of $\langle C\rangle$ can be obtained from performing a Taylor expansions of the mean total costs given by (\ref{Crbmlin}), (\ref{Crbmquad}), (\ref{Crbblin}) or (\ref{Crbbquad}), as appropriate for the case of interest.

We also need to expand $P_{\text{s}}$ in each ensemble, expressions for which are given by the integrals (\ref{Prbm}) and (\ref{Prbb}). To perform these expansions, it is helpful to define $s = u+R$, so that they become
\begin{align}
    P_{\text{s}}^{\text{RBM}} &= {\rm e}^{-R}\int_\Gamma \frac{{\rm d}u}{2\pi i}{\rm e}^u  \frac{1}{s-R} \frac{s}{R+(s-R){\rm e}^{M\sqrt{2s}}}\;, \label{p_hit_RBM2}\\
    P_{\text{s}}^{\text{RBB}} &= \frac{\sqrt{\pi}{\rm e}^{-R}}{\sqrt{\pi R}\erf \left( \sqrt{R} \right)+{\rm e}^{-R}} \int_\Gamma \frac{ds}{2\pi i} {\rm e}^s  \frac{\sqrt{s}}{s-R} \frac{R+(s-R) {\rm e}^{-M\sqrt{2s}}}{R+(s-R) e^{M\sqrt{2s}}}\;. \label{p_hit_RBB2}
\end{align}
The procedure now is to expand these expressions as a power series in $R$, and invert term-by-term. Up to second order, we find for the RBM case the expansion
\begin{align}
     P^{\text{RBM}}_{\text{s}} = & g_0(M) + g_1(M)R + g_2(M)\frac{R^2}{2}+ \ldots \;, \label{phit_expansion_RBM_S}
\end{align}
where the coefficients $g_i(M)$ are given by the integrals
\begin{align}
    g_0(M) = &\int_\Gamma \frac{{\rm d}s}{2\pi i} {\rm e}^s \frac{{\rm e}^{-\sqrt{2} M \sqrt{s}}}{s} = \text{erfc}\left(\frac{M}{\sqrt{2}}\right) \\[1ex]
    g_1(M) = &\int_\Gamma \frac{{\rm d}s}{2\pi i} {\rm e}^s \frac{{\rm e}^{-2 \sqrt{2} M \sqrt{s}} \left(-1-{\rm e}^{\sqrt{2} M \sqrt{s}} (-2+s)\right)}{s^2} \\[1ex]
   g_2(M) = &\int_\Gamma \frac{{\rm d}s}{2\pi i} {\rm e}^s \frac{{\rm e}^{-3 \sqrt{2} M \sqrt{s}} \left(2+2 {\rm e}^{\sqrt{2} M \sqrt{s}} (-3+s)+{\rm e}^{2 \sqrt{2} M \sqrt{s}} \left(6-4 s+s^2\right)\right)}{s^3} \;,
\end{align}
each of which can, like $g_0(M)$, be expressed in a closed form in terms of error functions. Explicit expressions are provided in an accompanying Mathematica notebook uploaded to \href{https://doi.org/10.7488/ds/7711}{DataShare}.

Similarly for RBB, we have
\begin{align}
    P^{\text{RBB}}_{\text{s}} = & h_0(M) + h_1(M)R + h_2(M)\frac{R^2}{2} + \ldots \;,  \label{phit_expansion_RBB_S}
\end{align}
where
\begin{align}
    h_0(M) =& \int_\Gamma \frac{{\rm d}s}{2\pi i}{\rm e}^s \frac{{\rm e}^{-2 \sqrt{2} M \sqrt{s}} \sqrt{\pi }}{\sqrt{s}} = {\rm e}^{-2 M^2}\;,\\[1ex]
    h_1(M) = &\int_\Gamma \frac{{\rm d}s}{2\pi i} {\rm e}^s \frac{{\rm e}^{-3 \sqrt{2} M \sqrt{s}} \sqrt{\pi } \left(-1+{\rm e}^{2 \sqrt{2} M \sqrt{s}}+{\rm e}^{\sqrt{2} M \sqrt{s}} (1-2 s)\right)}{s^{3/2}} \;,\\[1ex]
   h_2(M) = &\int_\Gamma \frac{{\rm d}s}{2\pi i}e^s \frac{2 {\rm e}^{-4 \sqrt{2} M \sqrt{s}} \sqrt{\pi } \left(3+6 {\rm e}^{\sqrt{2} M \sqrt{s}} (-1+s)-6 {\rm e}^{3 \sqrt{2} M \sqrt{s}} (-1+s)+2 {\rm e}^{2 \sqrt{2} M \sqrt{s}} s (-3+4s)\right)}{3 s^{5/2}}
\end{align}
and which again have closed-form expressions.

A similar process can be used to obtain the terms beyond the quadratic term. Note that in $R \to 0$ limit, \eqref{phit_expansion_RBM_S} and \eqref{phit_expansion_RBB_S} reduce to known results without resetting:  $P^{\text{RBM}}_{\text{s}} = \text{erfc}\left(\frac{M}{\sqrt{2}}\right)$ \cite{Redner} and $P^{\text{RBB}}_{\text{s}} = {\rm e}^{-2M^2}$ \cite{BMS22}.

The coefficients $a_i$ in \eqref{landau_expansion_S} can be written in terms of the terms of expansion of $P_{\text{S}}$ as
\begin{align}
    a_0 = &C_0 -\lambda  \log \left(g_0\right)\;,\\
    a_1 = &C_1-\lambda\frac{g_1}{g_0}\;,\\
    a_2 = &\frac{C_2}{2}-\lambda\frac{\left(-g_1^2+g_0 g_2\right)}{2g_0^2}\;,\\
    a_3 = &\frac{C_3}{6}-\lambda\frac{  \left(2 g_1^3-3 g_0 g_1 g_2+g_0^2 g_3\right)}{6 g_0^3}\;,\\
    a_4 = &\frac{C_4}{24}-\lambda\frac{  \left(-6 g_1^4+12 g_0 g_1^2 g_2-3 g_0^2 g_2^2-4 g_0^2 g_1 g_3+g_0^3 g_4\right)}{24 g_0^4}\;,
\end{align}
where $C_n = \frac{d^n \expval{C}}{dR^n}\Big\vert_{R\to0^+}$. The $g_i$ should be substituted with $h_i$ in the RBB case.

We now discuss the different cases that occur for transitions in the global minimum of the profligacy $\xi$ as we vary $\lambda$.

\subsection{Classical continuous transition}

In this case $a_2 > 0$ in the expansion \eqref{landau_expansion_S} and  may ignore higher order terms.  The curve of continuous transition occurs when $a_1=0$. This is the usual scenario for a continuous transition seen in equilibrium systems \cite{Goldenfeld}. Continuous transition lines are seen in all four panels of Fig. \ref{fig:transitions}. 

\begin{figure}[tb]
\centering
    \begin{subfigure}{.45\textwidth}
		\centering
	    \includegraphics[width=\linewidth]{RBB_Landau_classical_continuous_1.pdf} 
		\caption{}
        \label{fig:c_c_1}
	\end{subfigure}
 %
    \begin{subfigure}{.45\textwidth}
		\centering
	    \includegraphics[width=\linewidth]{RBB_Landau_classical_continuous_2.pdf} 
		\caption{}
        \label{fig:c_c_2}
	\end{subfigure}
   %
 \caption{The figure presents classical continuous transition observed in $\xi$ for the case of RBB with linear cost per reset when $\lambda$ is varied for $M=1.0$. (a) The global minimum which is at $R^* = 0$ initially continuously transitions to the new global minimum $R^*$ in (b) as $\lambda$ is varied.}
 \label{fig:c_c}
\end{figure}

For the case of RBM the continuous transition condition,  $a_1(\lambda,M) = 0$, is satisfied at $\lambda^*(M)$  given by
%
\begin{align}
    \lambda^* =  \frac{d\expval{C}^\text{RBM}}{dR}\bigg\vert_{R \to 0^+}\times\frac{\text{erfc}\left( \frac{M}{\sqrt{2}} \right)}{g_1(M)}\;, \label{RBM_continious_transition}
\end{align}
with $\frac{d\expval{C}^{\text{RBM}}_{\text{lin}}}{dR}\big\vert_{R \to 0^+} = \frac{4}{3\sqrt{\pi}}$ and $\frac{d\expval{C}^{\text{RBM}}_{\text{quad}}}{dR}\big\vert_{R \to 0^+} = 1$.
However, since we consider the investment $\lambda$, to act as a penalty if the searcher does not find the target, we require $\lambda>0$. But $g_1(M)<0$ for $M>0.8198$ which suggests that a continuous transition cannot exist for RBM if the rescaled distance to the target is greater than $M = 0.8198$. Further, $a_1(\lambda^*,M)>0$ for all values $M<0.8198$, which implies that the system has a continuous transition for all values of $M<0.8198$. This exactly matches with the result obtained in the FIG.~\ref{fig:RBM_linear} and \ref{fig:RBM_quad} where no transitions are observed beyond the critical value of $M$. 

For the case of RBB, the continuous transition condition,  $a_1(\lambda,M) = 0$, is satisfied at $\lambda^*(M)$. There we obtain the curve of continuous transition ($a_1(\lambda, M)=0$) to be
\begin{align}
    \lambda^* = \frac{d\expval{C}}{dR}\bigg\vert_{R \to 0^+}\times \frac{e^{-2M^2}}{h_1(M)}\;. \label{RBB_continuous_transition}
\end{align}
where we have the  derivatives $\frac{d\expval{C}^{\text{RBB}}_{\text{lin}}}{dR}\big\vert_{R \to 0^+} = \sqrt{\pi}$ and $\frac{d\expval{C}^{\text{RBB}}_{\text{quad}}}{dR}\big\vert_{R \to 0^+} = \frac{8}{3}$. Since $h_1(M)>0$ for all values of $M$, we obtain a solution for $a_1 =0$ for all values of $M$ for RBB.
For small values of $\lambda^*$ this corresponds to a continuous transition, however for large values of $\lambda^*$ we find  that $a_2<0$ and we have to consider classical discontinuous transition which we now discuss.

\subsection{Classical discontinuous transition}

A discontinuous transition may occur when $a_1$ is positive,  $a_2$  is negative  but $a_3$ is positive. Then  we have a local minimum in the profligacy at a non-zero value of $R$ in addition to a boundary minimum at $R=0$. If on increasing $\lambda$ the  global minimum switches between these two local minima, we have a jump in $R^*$ from a zero to a non-zero value. This is the classical scenario for a discontinuous transition. A classical tricritical point  occurs when a continuous transition line meets a discontinuous transition line, which occurs when $a_1=a_2=0$.

\begin{figure}[tb]
\centering
    \begin{subfigure}{.45\textwidth}
		\centering
	    \includegraphics[width=\linewidth]{RBB_Landau_classical_discontinuous_1.pdf} 
		\caption{}
        \label{fig:c_dc_1}
	\end{subfigure}
 %
    \begin{subfigure}{.45\textwidth}
		\centering
	    \includegraphics[width=\linewidth]{RBB_Landau_classical_discontinuous_2.pdf} 
		\caption{}
        \label{fig:c_dc_2}
	\end{subfigure}
   %
 \caption{The figure presents classical discontinuous transition observed in $\xi$ for the case of RBB with linear cost per reset when $\lambda$ is varied for $M=0.63$. (a) The global minimum which is at $R^* = 0$ initially discontinuously transitions to the new global minimum $R^*$ in (b) when the local minima becomes the new global minima as $\lambda$ is varied.}
 \label{fig:c_dc}
\end{figure}

A classical tricritical point occurs in the case of RBB  with linear cost as is seen in Fig. \ref{fig:RBB_linear}. Then for $a_2>0$ we obtain a continuous transition at $a_1=0$ but for
$a_2<0$ there is a discontinuous transition and if $a_1 = a_2 = 0$ (and $a_3>0$), we obtain a  tricritical point.  To obtain the tricritical point for RBB with  linear cost per reset, we set $a_2(\lambda^*,M) = 0$, which gives
\begin{align}
     e^{-2M^{*2}}\frac{d^2 \expval{C}}{dR^2}\bigg\vert_{R \to 0^+} + e^{2M^{*2}}\lambda^* h_1^2(M^*)
    -\lambda^* h_2(M^*) = 0\;,
\end{align}
which upon solving yields the tricritical point $(M^*,\lambda^*) = (0.6333,8.4994)$. 
For $\lambda$ approaching  this point from above we have a classical discontinuous transition

\subsection{Non-classical discontinuous transition}

Finally we address an interesting scenario, which to our knowledge is a non-standard way of generating discontinuous transitions. This occurs  when $a_3<0$ and $a_4>0$ and we retain terms up to $R^4$ in the Landau-like expansion. This is the case for both  RBM and RBB with quadratic cost per reset in an intermediate range of $M$. The quartic  expansion in $R$ allows two local minima in the profligacy if $a_1<0$,
or one local minimum, plus a boundary minimum at $R=0$, if $a_1>0$.  In the latter case either a discontinuous transition to a non-zero value of $R^*$ can occur when the local minimum becomes the global minimum, or a continuous transition can occur when $a_1$ becomes negative; in the former case a discontinuous transition between two non-zero values of $R^*$ can occur when the global minimum switches between the two local minima. A sequence of a continuous transition (when $a_1$ turns negative) followed by a discontinuous transition (when the global minimum switches between the subsequent two local minima) generates the overhangs seen in Figs. \ref{fig:RBM_quad},\ref{fig:RBB_quad}. Thus the red dots in Figs. \ref{fig:RBM_quad},\ref{fig:RBB_quad}
are not classical tricritical points as can be verified by evaluating $a_2(\lambda^*,m) = 0$
For RBM evaluating this results in two different values $m^*_{1,2}$, but evaluating the coefficient of $R^3$ gives $a_3(\lambda^*,m^*_{1,2})<0$. 

\begin{figure}[tb]
\centering
    \begin{subfigure}{.45\textwidth}
		\centering
	    \includegraphics[width=\linewidth]{RBB_Landau_non_classical_discontinuous_1.pdf} 
		\caption{}
        \label{fig:nc_dc_1}
	\end{subfigure}
 %
    \begin{subfigure}{.45\textwidth}
		\centering
	    \includegraphics[width=\linewidth]{RBB_Landau_non_classical_discontinuous_2.pdf} 
		\caption{}
        \label{fig:nc_dc_2}
	\end{subfigure}
   %
 \caption{The figure presents the non-classical discontinuous transition occurs observed in RBB with quadratic cost per reset as $\lambda$ is varied for $M = 0.707$. (a) The global minimum initially emerges continuously from $R = 0$ as $\lambda$ is varied. (b) As lambda is further increased, the second minimum becomes the global minima and there is a discontinuous transition of the optimal value $R^*$ to the new global minimum.}
 \label{fig:nc_dc}
\end{figure}

Finally we comment that, generally speaking, if the coefficients of $R^2$ or higher turn out to be negative, it indicates that a discontinuous transition might be possible. But the prediction of discontinuous transition must be considered carefully as the expansion is only quantitatively valid for small values of $R$. 

\section{Further interpretation of the profligacy function}
\label{sec:prof}

Consider a search company with $K$ independent Brownian searchers each of fixed duration $t_f$, 
starting and resetting at the origin with fixed rate $r$ in one dimension. For the moment, there is no target
to search for. For each walker, there is
a cost $C_{\rm traj}$ associated with its trajectory. The cost per walker
$\sum_{\rm traj} C_{\rm traj}/K$ converges, for large $K$, to
the mean cost $\langle C(r)\rangle$ associated with a trajectory of
fixed duration $t_f$ (irrespective of the target).  The mean cost $\langle C(r)\rangle$ is an increasing function of $r$.
Suppose that the total cost (or equivalently
the mean $\langle C(r)\rangle$) is constrained to have
a fixed value, say, $C_0$ (the fixed budget of the search company). 
Then, from $\langle C(r)\rangle=C_0$, one obtains a unique
value of $r$, say, $r_1$. This is the `predetermined' search parameter estimated by
the company, irrespective of where the target may lie.

Now, imagine putting a target at a distance $m$ from the origin
and the task of a searcher is to find the target in the least possible time, i.e.,
to maximize the success probability $P_s(r)$. 
However, the value $r_2$, that
maximizes $P_s(r)$ only, is typically not the same as $r_1$ (fixed by the budget).
So, one needs to find
a compromise. If we insist on a `fixed' budget $C_0$, then we have
no choice but to select the predetermined value $r_1$. One can optimize a bit better by
choosing $r$ to be different from the set value $r_1$, i.e., by
relaxing the hard cost constraint by a soft one. But this comes at a price.
Allowing
a bit more flexibility in the budget by exceeding $C_0$ incurs a penalty, 
parametrized by a temperature like factor $\lambda>0$, as an additional weight 
factor $\exp\left[-\frac{1}{\lambda}\, \left(\langle C(r)\rangle-C_0\right)\right]$, for
$\langle C(r)\rangle >C_0$. When $\lambda\to 0$, one recovers the
hard constraint. Then our goal is to
find the value of $r=r^*$ that maximizes the product of
$P_s(r)$ and this weight factor. This is equivalent 
to minimizing the profligacy defined by
\begin{equation}
\xi= \langle C(r)\rangle - \lambda\, P_s(r)
\label{weight.1}
\end{equation}
where we have ignored a global constant involving $C_0$ without any loss of generality.
Let us remark here that while the success probability $P_s(r)$ depends on
the target distance $m$, the `predetermined' reset parameter $r_1$
 and  cost function
$\langle C(r)\rangle$ are
independent of the target distance $m$.

\makeatletter\@input{xx.tex}\makeatother
\end{document}

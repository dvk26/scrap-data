{
    "paper_title": "Rethinking Kullback-Leibler Divergence in Knowledge Distillation for Large Language Models",
    "authors": [
        "Taiqiang Wu",
        "Chaofan Tao",
        "Jiahao Wang",
        "Zhe Zhao",
        "Ngai Wong"
    ],
    "publication_venue": "Under review as a conference paper at COLM 2024",
    "submission_date": "2024-04-03",
    "revised_dates": [
        "2024-04-03",
        "2024-04-03",
        "2024-04-03",
        "2024-04-03"
    ]
}